[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Numerical Methods for PDEs: An Interactive Journey",
    "section": "",
    "text": "0.1 Numerical Methods for PDEs: An Interactive Journey",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Numerical Methods for PDEs: An Interactive Journey</span>"
    ]
  },
  {
    "objectID": "index.html#levels",
    "href": "index.html#levels",
    "title": "Numerical Methods for PDEs: An Interactive Journey",
    "section": "1.1 Levels",
    "text": "1.1 Levels\n\nLevel 1: Origins of PDEs\nLevel 2: Classification of PDEs\nLevel 3: Physical Interpretation and boundary conditions\nLevel 4: Finite Difference Methods- Introduction with application to the Heat Eqaution\nLevel 5 : Hyperbolic PDEs - Wave Equation",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Numerical Methods for PDEs: An Interactive Journey</span>"
    ]
  },
  {
    "objectID": "chapters/level1_history_pdes.html",
    "href": "chapters/level1_history_pdes.html",
    "title": "2¬† Level 1: A Historical Glimpse of PDEs",
    "section": "",
    "text": "Pavni: Acharya, where did all these partial differential equations come from? They seem so abstract.\nAcharya: Ah, Pavni, they did not begin in abstraction. They began with strings, heat, and the mysteries of the heavens.\nPavni: Strings? You mean music?\nAcharya: Exactly! In 1746, d‚ÄôAlembert studied how a vibrating string produces sound. From that, he wrote down the wave equation. Soon after, Euler extended it to drums and membranes. So you see, music and mathematics are deeply connected.\nPavni: That‚Äôs beautiful! And the heat equation?\nAcharya: That came from Joseph Fourier in the early 1800s. He asked: How does heat spread through a solid body? His answer was the heat equation, and in solving it he gave us the gift of Fourier series.\nPavni: So Fourier series were born from studying heat?\nAcharya: Precisely. And then Laplace studied gravitational attraction and derived the Laplace equation, describing potentials in physics. Poisson later generalized it with the Poisson equation, where sources appear inside the field.\nPavni: So each new equation came from a real phenomenon.\nAcharya: Just so. Later, in the 19th century, Navier and Stokes wrote down the equations of fluid motion ‚Äî the Navier‚ÄìStokes equations. Even today, their mysteries are not fully solved.\nPavni: (smiling) So PDEs are not just formulas on paper. They are echoes of sound, flows of heat, gravity, and water.\nAcharya: Well said, Pavni. They are the language by which nature speaks to us.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Level 1: A Historical Glimpse of PDEs</span>"
    ]
  },
  {
    "objectID": "chapters/level2_classification_pdes.html",
    "href": "chapters/level2_classification_pdes.html",
    "title": "3¬† Level 2: Classification of PDEs",
    "section": "",
    "text": "3.1 Mini Quizzes\nQuiz 1: Identify the order\nWhich of the following is a second-order PDE?\n1. $ u_t + cu_x = 0 $\n2. $ u_t = u_{xx} $\n3. $ u u_x = 0 $\nQuiz 2: Linearity check\nWhich PDE is nonlinear?\n1. $ u_t = u_{xx} $\n2. $ u_t + u u_x = 0 $\nQuiz 3: Homogeneous or inhomogeneous\nClassify: $ u_{xx} + u_{yy} = f(x,y) $.\nQuiz 4: Type of second-order PDE\nFor $ u_{xx} + 2u_{xy} + u_{yy} = 0 $, compute $ B^2 - 4AC $. What type is it?\nQuiz 5: Physical meaning\nMatch each equation with its physical interpretation:\n- Heat equation\n- Wave equation\n- Laplace‚Äôs equation",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Level 2: Classification of PDEs</span>"
    ]
  },
  {
    "objectID": "chapters/level2_classification_pdes.html#mini-quizzes",
    "href": "chapters/level2_classification_pdes.html#mini-quizzes",
    "title": "3¬† Level 2: Classification of PDEs",
    "section": "",
    "text": "TipAnswer 1\n\n\n\n\n\nEquation (2) $ u_t = u_{xx} $ is second-order because of the \\(u_{xx}\\) term.\n\n\n\n\n\n\n\n\n\n\n\nTipAnswer 2\n\n\n\n\n\nEquation (2) is nonlinear because of the product term \\(u u_x\\).\n\n\n\n\n\n\n\n\n\n\n\nTipAnswer 3\n\n\n\n\n\nIt is inhomogeneous, since the right-hand side is not zero.\n\n\n\n\n\n\n\n\n\n\n\nTipAnswer 4\n\n\n\n\n\nHere, \\(A = 1, B = 2, C = 1\\).\n$ B^2 - 4AC = 2^2 - 4(1)(1) = 0 $.\nSo it is parabolic.\n\n\n\n\n\n\nSteady state\n\nWave-like motion\n\nDiffusion in time\n\n\n\n\n\n\n\nTipAnswer 5\n\n\n\n\n\n\nHeat equation ‚Üí (c) Diffusion in time\n\nWave equation ‚Üí (b) Wave-like motion\n\nLaplace‚Äôs equation ‚Üí (a) Steady state",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Level 2: Classification of PDEs</span>"
    ]
  },
  {
    "objectID": "chapters/level3_PDE_BCs.html",
    "href": "chapters/level3_PDE_BCs.html",
    "title": "4¬† Level 3: PDEs, their Physical Meaning, and Boundary Conditions",
    "section": "",
    "text": "4.1 Dirichlet Condition\nPavni: Acharya, PDEs still feel mysterious. What do they really mean?\nAcharya: Good question. PDEs describe how a quantity changes with respect to both time and space. Think of:\n- Heat spreading in a rod\n- Waves traveling along a string\n- Fluid flowing through a pipe\nAll of these involve rates of change in multiple directions, and that‚Äôs why PDEs come into play.\nPavni: So PDEs are the language of physics in extended domains?\nAcharya: Exactly. But to make their solutions unique and physically meaningful, we need boundary conditions. Let‚Äôs explore them one by one.\nAcharya: Dirichlet means fixing the value of the solution at the boundary.\nPavni: Like holding both ends of a rod at 100 ¬∞C?\nAcharya: Precisely. It represents physical situations where the boundary is controlled by an external source‚Äîlike contact with a thermostat.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Level 3: PDEs, their Physical Meaning, and Boundary Conditions</span>"
    ]
  },
  {
    "objectID": "chapters/level3_PDE_BCs.html#neumann-condition",
    "href": "chapters/level3_PDE_BCs.html#neumann-condition",
    "title": "4¬† Level 3: PDEs, their Physical Meaning, and Boundary Conditions",
    "section": "4.2 Neumann Condition",
    "text": "4.2 Neumann Condition\nAcharya: Neumann means fixing the derivative, often representing flux.\nPavni: So in the rod, saying no heat flows out means the temperature gradient at the end is zero?\nAcharya: Exactly. That‚Äôs an insulated boundary.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Level 3: PDEs, their Physical Meaning, and Boundary Conditions</span>"
    ]
  },
  {
    "objectID": "chapters/level3_PDE_BCs.html#robin-mixed-condition",
    "href": "chapters/level3_PDE_BCs.html#robin-mixed-condition",
    "title": "4¬† Level 3: PDEs, their Physical Meaning, and Boundary Conditions",
    "section": "4.3 Robin (Mixed) Condition",
    "text": "4.3 Robin (Mixed) Condition\nAcharya: Robin mixes the two:\n\\[\na u + b \\frac{\\partial u}{\\partial n} = c.\n\\]\nPavni: Is that like when heat escapes to the air?\nAcharya: Yes‚Äîconvective cooling. The flux depends on both the temperature at the boundary and the environment.\n\n\n\nüí° Quick Recap\n\n\nDirichlet ‚Üí Value fixed (e.g., temperature = 100 ¬∞C).\n\nNeumann ‚Üí Flux fixed (e.g., insulated boundary).\n\nRobin ‚Üí Combination (e.g., convective heat loss).\n\n\n\n\n4.3.1 üìù Mini-Quiz\n\nA vibrating string held fixed at both ends uses which boundary condition?\n\n\n\nAnswer\n\nDirichlet. The displacement of the string is zero at both ends.\n\nIf a wall is perfectly insulated, what type of boundary condition applies to temperature?\n\n\n\nAnswer\n\nNeumann. The derivative (temperature gradient) is zero, meaning no heat flux.\n\nWhich boundary condition models cooling of hot coffee in a room?\n\n\n\nAnswer\n\nRobin. Heat loss depends on both the coffee‚Äôs surface temperature and the room temperature (convection).\n\n\n\nPavni: Now I see it! PDEs tell the story inside the domain, and boundary conditions set the rules at the edges.\nAcharya: Well said. Together, they form the complete model of a physical system.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Level 3: PDEs, their Physical Meaning, and Boundary Conditions</span>"
    ]
  },
  {
    "objectID": "chapters/level4_finite_differences.html",
    "href": "chapters/level4_finite_differences.html",
    "title": "5¬† Level 3: Finite Differences and the Heat Equation",
    "section": "",
    "text": "5.1 Application: The Heat Equation",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Level 3: Finite Differences and the Heat Equation</span>"
    ]
  },
  {
    "objectID": "chapters/level4_finite_differences.html#application-the-heat-equation",
    "href": "chapters/level4_finite_differences.html#application-the-heat-equation",
    "title": "5¬† Level 3: Finite Differences and the Heat Equation",
    "section": "",
    "text": "Acharya: Consider the 1D heat equation: \\[\nu_t = \\alpha^2 u_{xx}^2, \\quad 0 &lt; x &lt; 1,\\; t&gt;0\n\\] with boundary conditions \\(u(0,t) = u(1,t) = 0\\) and initial profile \\(u(x,0) = f(x)\\).\nWe set up a grid: - In space: \\(x_i = i\\Delta x,\\; i=0,\\dots,N\\)\n- In time: \\(t^n = n\\Delta t,\\; n=0,1,2,\\dots\\)\nAt each point, let \\(u_i^n \\approx u(x_i,t^n)\\).\nPavni: And now we replace derivatives?\nAcharya: Correct.\n- Time derivative (forward difference): \\[\n  u_t(x_i,t^n) \\approx \\frac{u_i^{n+1} - u_i^n}{\\Delta t}\n  \\] - Spatial second derivative (central difference): \\[\n  u_{xx}(x_i,t^n) \\approx \\frac{u_{i-1}^n - 2u_i^n + u_{i+1}^n}{(\\Delta x)^2}\n  \\]\nPlugging these into the PDE, we get: \\[\n\\frac{u_i^{n+1} - u_i^n}{\\Delta t} = \\alpha^2 \\,\\frac{u_{i-1}^n - 2u_i^n + u_{i+1}^n}{(\\Delta x)^2}.\n\\]\nRearranging: \\[\nu_i^{n+1} = u_i^n + \\lambda\\,(u_{i-1}^n - 2u_i^n + u_{i+1}^n),\n\\] where \\(\\lambda = \\frac{\\alpha^2 \\Delta t}{(\\Delta x)^2}\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Level 3: Finite Differences and the Heat Equation</span>"
    ]
  },
  {
    "objectID": "chapters/level4_finite_differences.html#stability-condition",
    "href": "chapters/level4_finite_differences.html#stability-condition",
    "title": "5¬† Level 3: Finite Differences and the Heat Equation",
    "section": "5.2 Stability Condition",
    "text": "5.2 Stability Condition\n\nPavni: So we can just keep applying this formula to march forward in time?\nAcharya: Yes, but with a caveat. This scheme, called FTCS (Forward Time, Central Space), is only stable if: \\[\n\\lambda \\leq \\tfrac{1}{2}.\n\\]\nPavni: So if \\(\\Delta t\\) is too large, the scheme fails?\nAcharya: Exactly. The numerical solution will blow up, even though the true solution is stable. Choosing \\(\\Delta t\\) small enough ensures stability.\n\n\n\n\n\n\n\nNoteWhy the FTCS stability condition is \\(\\lambda \\leq \\tfrac{1}{2}\\)\n\n\n\n\n\nIf the update is \\[\nu^{(n+1)} = A u^{(n)},\n\\] and the initial error is \\(e^0\\), then after \\(n\\) steps the error is \\[\ne^{(n)} = A^n e^0.\n\\]\nUsing an induced matrix norm: \\[\n\\|e^{(n)}\\| = \\|A^n e^0\\| \\;\\le\\; \\|A^n\\|\\,\\|e^0\\|\n\\;\\le\\; \\|A\\|^n \\|e^0\\|.\n\\]\n\nIf \\(\\|A\\|\\le 1\\), the error never grows.\n\nIf \\(\\|A\\|&lt;1\\), the error decays as \\(n\\to\\infty\\).\n\nIn general, the asymptotic condition is that the spectral radius \\(\\rho(A)&lt;1\\).\n\n\n\n5.2.0.1 Eigenvalues of the FTCS matrix\nFor the FTCS tridiagonal matrix \\(A\\) (symmetric Toeplitz), the eigenvalues are \\[\n\\mu_k = 1 - 4 \\lambda \\,\\sin^2\\!\\left(\\frac{k\\pi}{2(N-1)}\\right),\n\\qquad k=1,2,\\dots,N-2,\n\\] where \\(\\lambda = \\dfrac{\\alpha^2 \\Delta t}{(\\Delta x)^2}\\).\nThus the spectral radius is \\[\n\\rho(A) = \\max_{1\\le k \\le N-2} \\big|\\mu_k\\big|\n= \\max_{1\\le k \\le N-2} \\left|1 - 4r \\sin^2\\!\\left(\\tfrac{k\\pi}{2(N-1)}\\right)\\right|.\n\\]\n\n\n\n5.2.0.2 Stability condition\n\nAs \\(N\\to\\infty\\) (i.e.¬†\\(\\Delta x \\to 0\\)), the maximum of \\(\\sin^2(\\cdot)\\) tends to \\(1\\).\n\nTherefore the most restrictive case is \\[\n|1 - 4 \\lambda| \\le 1.\n\\]\nThis simplifies to \\[\n0 \\;\\le\\; \\lambda \\;\\le\\; \\tfrac{1}{2}.\n\\]\n\n\n‚úÖ Thus, the FTCS scheme is stable if and only if \\[\n\\lambda = \\frac{\\alpha \\Delta t}{(\\Delta x)^2} \\;\\le\\; \\tfrac{1}{2}.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Level 3: Finite Differences and the Heat Equation</span>"
    ]
  },
  {
    "objectID": "chapters/level4_finite_differences.html#mini-quizzes",
    "href": "chapters/level4_finite_differences.html#mini-quizzes",
    "title": "5¬† Level 3: Finite Differences and the Heat Equation",
    "section": "5.3 Mini-Quizzes",
    "text": "5.3 Mini-Quizzes\n\nQuiz 1:\nLet \\(u(x) = x^2\\). With \\(\\Delta x = 0.1\\), approximate \\(u'(1)\\) using:\n1. Forward difference\n2. Central difference\nCompare with the exact derivative \\(u'(1) = 2\\). Which is more accurate?\n\n\n\n\n\n\n\nTipAnswer 1\n\n\n\n\n\n\nForward difference: \\[\n\\frac{u(1+\\Delta x)-u(1)}{\\Delta x}=\\frac{(1.1)^2-1^2}{0.1}=\\frac{1.21-1}{0.1}=2.1.\n\\]\nCentral difference: \\[\n\\frac{u(1+\\Delta x)-u(1-\\Delta x)}{2\\Delta x}\n=\\frac{(1.1)^2-(0.9)^2}{0.2}=\\frac{1.21-0.81}{0.2}=2.0.\n\\]\nExact derivative: \\(u'(1)=2\\).\n\nConclusion: The central difference gives the exact value here (error \\(0\\)), while the forward difference has error \\(0.1\\). Central is more accurate (as expected ‚Äî it is second-order).\n\n\n\n\n\nQuiz 2:\nSuppose \\(\\alpha = 1\\), \\(\\Delta x = 0.1\\). What is the maximum \\(\\Delta t\\) for stability in the explicit scheme?\n(Hint: \\(\\lambda = \\dfrac{\\alpha \\Delta t}{(\\Delta x)^2} \\leq \\tfrac{1}{2}\\).)\n\n\n\n\n\n\n\nTipAnswer 2\n\n\n\n\n\nWe need \\[\n\\lambda=\\frac{\\alpha\\,\\Delta t}{(\\Delta x)^2}\\le\\frac{1}{2}.\n\\] With \\(\\alpha=1\\) and \\(\\Delta x=0.1\\), \\((\\Delta x)^2=0.01\\). So \\[\n\\frac{\\Delta t}{0.01}\\le\\frac{1}{2}\\quad\\Rightarrow\\quad\n\\Delta t \\le 0.01\\times\\frac{1}{2}=0.005.\n\\]\nMaximum allowable \\(\\displaystyle \\Delta t = 0.005\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Level 3: Finite Differences and the Heat Equation</span>"
    ]
  },
  {
    "objectID": "chapters/level4_finite_differences.html#heat-equation-matrix-method-with-non-zero-dirichlet-conditions",
    "href": "chapters/level4_finite_differences.html#heat-equation-matrix-method-with-non-zero-dirichlet-conditions",
    "title": "5¬† Level 3: Finite Differences and the Heat Equation",
    "section": "5.4 Heat equation ‚Äî Matrix Method with Non-zero Dirichlet Conditions",
    "text": "5.4 Heat equation ‚Äî Matrix Method with Non-zero Dirichlet Conditions\n\nPavni: We already saw how to discretize the heat equation with FTCS. But can we write the whole scheme in a more compact way?\nAcharya: Yes. That‚Äôs where the matrix method comes in. Let‚Äôs recall the PDE: \\[\nu_t = \\alpha^2 u_{xx}, \\quad 0 &lt; x &lt; 1, \\; t &gt; 0,\n\\] with Dirichlet conditions \\[\nu(0,t) = L, \\qquad u(1,t) = R,\n\\] and initial condition \\(u(x,0)=f(x)\\).\nPavni: So we still set up the grid in space and time?\nAcharya: Exactly. The FTCS update at interior nodes is \\[\nu_i^{j+1} = u_i^j + \\lambda \\,(u_{i-1}^j - 2u_i^j + u_{i+1}^j),\n\\quad i=1,\\dots,N_x-2,\n\\] where \\(\\lambda = \\tfrac{\\alpha^2 \\Delta t}{\\Delta x^2}\\).\nPavni: That‚Äôs a lot of coupled equations. How do we collect them?\nAcharya: We put all interior values into a vector \\[\nu^{(j)} =\n\\begin{bmatrix}\nu_1^j \\\\\nu_2^j \\\\\n\\vdots \\\\\nu_{N_x-2}^j\n\\end{bmatrix}.\n\\]\nPavni: And the update rule becomes a matrix multiplication?\nAcharya: Yes. We can write \\[\nu^{(j+1)} = A\\,u^{(j)} + b,\n\\] where \\(A\\) is tridiagonal and \\(b\\) accounts for the boundary conditions: \\[\nA =\n\\begin{bmatrix}\n1-2\\lambda & \\lambda     &        &        &   \\\\\n\\lambda     & 1-2\\lambda & \\lambda      &        &   \\\\\n      & \\ddots & \\ddots & \\ddots &   \\\\\n      &        & \\lambda      & 1-2\\lambda   & \\lambda \\\\\n      &        &        & \\lambda      & 1-2\\lambda\n\\end{bmatrix}, \\qquad\nb =\n\\begin{bmatrix}\n\\lambda L \\\\\n0 \\\\\n\\vdots \\\\\n0 \\\\\n\\lambda R\n\\end{bmatrix}.\n\\]\nPavni: So if \\(L=R=0\\), then \\(b=0\\) and we just have \\(u^{(j+1)} = A u^{(j)}\\).\nAcharya: Precisely. That‚Äôs the beauty of the matrix method: it organizes the scheme into a linear algebra update.\n\n\n\n5.4.1 Implementation in Python\nLet us now implement the method in Python and compare with the exact solution for \\(f(x)=\\sin(\\pi x)\\): \\[\nu(x,t) = e^{-\\pi^2 \\alpha t}\\,\\sin(\\pi x).\n\\]\n\n\nShow code\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nalpha = 1.0\nNx    = 50\nT     = 0.1\nL, R  = 0.0, 0.0\n\ndx = 1.0/(Nx-1)\ndt_max = dx*dx/(2*alpha)\ns  = 0.4\ndt = s*dt_max\nNt = int(T/dt)\ndt = T/Nt\nr  = alpha*dt/dx**2\n\nx  = np.linspace(0.0, 1.0, Nx)\nu0 = np.sin(np.pi * x)\n\nm = Nx - 2\nmain = (1 - 2*r) * np.ones(m)\noff  = r * np.ones(m-1)\nA = np.diag(main) + np.diag(off,1) + np.diag(off,-1)\n\nb = np.zeros(m)\nb[0], b[-1] = r*L, r*R\n\nu = u0.copy()\nu_in = u[1:-1].copy()\nsnapshots = []\nsnap_times = np.linspace(0, Nt-1, 5, dtype=int)\n\nfor j in range(Nt):\n    u_in = A @ u_in + b\n    u[1:-1] = u_in\n    if j in snap_times or j == Nt-1:\n        snapshots.append((j*dt, u.copy()))\n\nplt.figure(figsize=(8,4))\nfirst_exact = True\nfor t_here, u_snap in snapshots:\n    plt.plot(x, u_snap, label=f\"num t={t_here:.3f}\")\n    u_exact = np.exp(-np.pi**2*alpha*t_here) * np.sin(np.pi*x)\n    if first_exact:\n        plt.plot(x, u_exact, 'k--', linewidth=1.2, label='exact solution')\n        first_exact = False\n    else:\n        plt.plot(x, u_exact, 'k--', linewidth=1.2, label=\"_nolegend_\")\n\nplt.xlabel(\"x\"); plt.ylabel(\"u(x,t)\")\nplt.title(\"Heat equation: numerical vs exact\")\nplt.legend(fontsize=\"small\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n5.4.2 Remarks\n\nThe linear algebra structure \\(u^{(j+1)} = A u^{(j)} + b\\) makes the scheme compact and systematic.\n\nThe stability restriction \\(\\lambda \\leq \\tfrac{1}{2}\\) follows from analyzing the eigenvalues of \\(A\\).\n\nFor large \\(N_x\\), \\(A\\) is sparse and tridiagonal ‚Äî in practice, use scipy.sparse.diags for efficiency.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Level 3: Finite Differences and the Heat Equation</span>"
    ]
  },
  {
    "objectID": "chapters/level4_finite_differences.html#backward-difference-implicit-scheme-for-the-heat-equation",
    "href": "chapters/level4_finite_differences.html#backward-difference-implicit-scheme-for-the-heat-equation",
    "title": "5¬† Level 3: Finite Differences and the Heat Equation",
    "section": "5.5 Backward Difference (Implicit) Scheme for the Heat Equation",
    "text": "5.5 Backward Difference (Implicit) Scheme for the Heat Equation\n\nPavni: Acharya, the FTCS scheme works only if \\(\\lambda \\leq \\tfrac{1}{2}\\). Is there a method that avoids this restriction?\nAcharya: Yes. We can use a backward difference in time, together with the same central difference in space. This gives the Backward Euler scheme, which is implicit but unconditionally stable.\nPavni: Implicit? What does that mean?\nAcharya: It means that the new values \\(u^{n+1}\\) appear on both sides of the equation, so we must solve a system of equations at each time step.\n\n\n\n5.5.1 Derivation\nStart from the PDE: \\[\nu_t = \\alpha^2 u_{xx}.\n\\]\n\nApproximate the time derivative with a backward difference: \\[\nu_t(x_i,t^{n+1}) \\;\\approx\\; \\frac{u_i^{\\,n+1} - u_i^{\\,n}}{\\Delta t}.\n\\]\nApproximate the spatial second derivative at the new time level: \\[\nu_{xx}(x_i,t^{n+1}) \\;\\approx\\; \\frac{u_{i-1}^{\\,n+1} - 2u_i^{\\,n+1} + u_{i+1}^{\\,n+1}}{(\\Delta x)^2}.\n\\]\n\nThe scheme becomes: \\[\n\\frac{u_i^{\\,n+1} - u_i^{\\,n}}{\\Delta t}\n= \\alpha^2 \\,\\frac{u_{i-1}^{\\,n+1} - 2u_i^{\\,n+1} + u_{i+1}^{\\,n+1}}{(\\Delta x)^2}.\n\\]\nRearrange: \\[\n- \\lambda\\, u_{i-1}^{\\,n+1} + (1+2\\lambda)\\,u_i^{\\,n+1} - \\lambda\\, u_{i+1}^{\\,n+1} = u_i^{\\,n},\n\\qquad\n\\lambda = \\frac{\\alpha^2 \\Delta t}{(\\Delta x)^2}.\n\\]\n\n\n\n5.5.2 Matrix Form\nLet \\(u^{(n)}\\) be the vector of interior values at time step \\(n\\). Then \\[\nB u^{(n+1)} = u^{(n)},\n\\] where \\[\nB =\n\\begin{bmatrix}\n1+2\\lambda & -\\lambda     &            &            &   \\\\\n-\\lambda    & 1+2\\lambda  & -\\lambda   &            &   \\\\\n            & \\ddots      & \\ddots     & \\ddots     &   \\\\\n            &             & -\\lambda   & 1+2\\lambda & -\\lambda \\\\\n            &             &            & -\\lambda   & 1+2\\lambda\n\\end{bmatrix}_{(N_x-2)\\times(N_x-2)}.\n\\]\nSo each step requires solving the linear system \\[\nu^{(n+1)} = B^{-1} u^{(n)}.\n\\]\n\n\n\n5.5.3 Stability\n\nPavni: Doesn‚Äôt that make it more expensive than FTCS?\nAcharya: It does, because we must solve a tridiagonal system at every time step.\nBut the reward is unconditional stability: for any \\(\\Delta t &gt; 0\\) and \\(\\Delta x &gt; 0\\), the scheme does not blow up.\nPavni: So no restriction like \\(\\lambda \\leq \\tfrac{1}{2}\\)?\nAcharya: Exactly. Backward Euler is stable for all \\(\\lambda\\).\nIt is only first-order accurate in time (like FTCS), but still second-order in space.\n\n\n\n\n5.5.4 Remarks\n\nBackward Euler is more robust but requires solving a linear system at each step.\n\nFor large systems, efficient algorithms like the Thomas algorithm (specialized Gaussian elimination for tridiagonal matrices) are used.\n\nIn practice, one balances cost (explicit FTCS, cheap but conditionally stable) against robustness (implicit Backward Euler, unconditionally stable).\n\n\n\n\n\n\n\nNoteWhy the Backward Euler scheme is unconditionally stable\n\n\n\n\n\nIf the update is\n\\[\nu^{(n+1)} = A u^{(n)},\n\\]\nand the initial error is \\(e^0\\), then after \\(n\\) steps the error is\n\\[\ne^{(n)} = A^n e^0.\n\\]\nAs before, the asymptotic condition is that the spectral radius \\(\\rho(A)&lt;1\\).\n\n\n5.5.4.1 Eigenvalues of the Backward Euler iteration matrix\nThe Backward Euler scheme for the heat equation is\n\\[\n\\frac{U^{n+1} - U^n}{\\Delta t} = \\alpha^2 A U^{n+1},\n\\] which rearranges to\n\\[\nU^{n+1} = (I - \\lambda A)^{-1} U^n,\n\\qquad \\lambda = \\frac{\\alpha^2 \\Delta t}{(\\Delta x)^2}.\n\\]\n\nIf \\(\\lambda_i(A)\\) are the eigenvalues of the discrete Laplacian \\(A\\),\nthen the eigenvalues of the iteration matrix are \\[\n\\mu_i = \\frac{1}{1 - \\lambda_i(A)}.\n\\]\nFor the 1D Laplacian with Dirichlet BCs, \\[\n\\lambda_i(A) = -4 \\sin^2\\!\\left(\\frac{i\\pi}{2m}\\right),\n\\qquad i=1,2,\\dots,m-1.\n\\]\n\nThus \\[\n\\mu_i = \\frac{1}{1 + 4\\lambda \\sin^2\\!\\left(\\frac{i\\pi}{2m}\\right)}.\n\\]\n\n\n\n5.5.4.2 Stability condition\n\nSince \\(\\lambda&gt;0\\) and \\(\\sin^2(\\cdot)\\ge0\\),\nthe denominator is always greater than \\(1\\).\n\nTherefore \\[\n0 &lt; \\mu_i &lt; 1, \\qquad \\forall i.\n\\]\n\nThis means all eigenvalues of the iteration matrix lie strictly inside the unit circle.\n\n‚úÖ Thus, the Backward Euler scheme is unconditionally stable: - No restriction on \\(\\Delta t\\).\n- Every mode decays monotonically.\n- In contrast, FTCS required \\(\\lambda \\le \\tfrac{1}{2}\\) for stability.\n\n\n\n\n\n\n5.5.5 Interactive plots to see the eigenvalues of FTCS and Backward Differencce methods\n\n\n                            \n                                            \n\n\n                            \n                                            \n\n\n\nHow to interact with the plots - Move the slider to change \\(\\lambda = \\tfrac{\\alpha^2 \\Delta t}{(\\Delta x)^2}\\).\n- FTCS plot: notice that for \\(\\lambda &gt; 0.5\\) some eigenvalues leave \\([-1,1]\\), indicating instability.\n- Backward Euler plot: eigenvalues always remain in \\((0,1)\\), showing unconditional stability.\n- Hover over points to see their values, zoom by dragging, double-click to reset.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Level 3: Finite Differences and the Heat Equation</span>"
    ]
  },
  {
    "objectID": "chapters/level5_Wave_Equation.html",
    "href": "chapters/level5_Wave_Equation.html",
    "title": "6¬† Level 4: Hyperbolic PDEs: Wave Equation",
    "section": "",
    "text": "Pavni: We‚Äôve studied the heat equation as an example of a parabolic PDE. What about hyperbolic ones? Where do we begin?\nAcharya: A natural starting point is the wave equation:\n\\[\nu_{tt} = c^2 u_{xx}.\n\\]\nPavni: Oh! That‚Äôs the equation for vibrations of a string, right?\nAcharya: Exactly. Imagine a taut string. Newton‚Äôs law applied to a small element gives:\n\\[\n\\rho u_{tt} = T u_{xx},\n\\]\nwhere \\(T\\) is tension and \\(\\rho\\) is density. Dividing through, we get\n\\[\nu_{tt} = \\left(\\tfrac{T}{\\rho}\\right) u_{xx},\n\\]\nso the wave speed is \\(c = \\sqrt{T/\\rho}\\).\nPavni: So physically, it describes oscillations moving along the string. But why do we call this hyperbolic?\nAcharya: Let‚Äôs look at the general second-order PDE in two variables:\n\\[\nA u_{xx} + 2B u_{xt} + C u_{tt} = 0.\n\\]\nIts type depends on the discriminant \\(D = B^2 - AC\\).\n- If \\(D &lt; 0\\), it‚Äôs elliptic.\n- If \\(D = 0\\), parabolic.\n- If \\(D &gt; 0\\), hyperbolic.\nPavni: For the wave equation, we have \\(A = -c^2, B=0, C=1\\). Then\n\\[\nD = B^2 - AC = c^2 &gt; 0.\n\\]\nAcharya: Exactly ‚Äî that‚Äôs why it‚Äôs hyperbolic.\nPavni: Does that mean it has some special geometry?\nAcharya: Yes. Notice how the operator factors:\n\\[\nu_{tt} - c^2 u_{xx} = (\\partial_t - c\\partial_x)(\\partial_t + c\\partial_x) u.\n\\]\nThis reveals the characteristics: the lines\n\\[\nx - ct = \\text{constant}, \\quad x + ct = \\text{constant}.\n\\]\nPavni: So along those lines, the solution behaves in a simple way?\nAcharya: Precisely. The general solution is\n\\[\nu(x,t) = f(x - ct) + g(x + ct).\n\\]\nIt‚Äôs just the sum of two waves, one traveling right, one traveling left.\nPavni: That‚Äôs beautiful! It really captures the idea of finite-speed propagation.\nAcharya: Indeed. If you disturb the string at one point, the influence spreads only within the cone \\(|x-x_0| \\leq c(t-t_0)\\).\nThat‚Äôs the hallmark of hyperbolic PDEs: signals travel with finite speed, unlike diffusion where influence is instant.\nPavni: So the wave equation is the prototype for hyperbolic PDEs?\nAcharya: Exactly. From here, we can explore more complex hyperbolic equations ‚Äî nonlinear ones, conservation laws, and shock waves ‚Äî but the wave equation is where the story begins.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Level 4: Hyperbolic PDEs: Wave Equation</span>"
    ]
  }
]